{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"text-align:center;font-size:200%;\">\n","    <b>Model Explainability in Industrial Image Detection</b>\n","</h2>\n","<h3  style=\"text-align:center;\">Keywords : \n","    <span style=\"border-radius:7px;background-color:limegreen;color:white;padding:7px;\">Image Classification</span>\n","    <span style=\"border-radius:7px;background-color:limegreen;color:white;padding:7px;\">Data Augmentation</span>\n","    <span style=\"border-radius:7px;background-color:limegreen;color:white;padding:7px;\">CNN</span><br><br>\n","    <span style=\"border-radius:7px;background-color:limegreen;color:white;padding:7px;\">Model Explanation</span>\n","    <span style=\"border-radius:7px;background-color:limegreen;color:white;padding:7px;\">Error Analysis</span>\n","</h3>\n","\n","<hr>\n","\n","<a id='top'></a>\n","<h2 style=\"font-size:150%;\"><span id='top'>Table of Contents</span></h2>\n","<blockquote>\n","    <ol>\n","        <li><a href=\"#Overview\">Overview</a></li>\n","        <ul>\n","            <li><a href=\"#Task-Detail\">Task Detail</a></li>\n","            <li><a href=\"#About-Dataset\">About Dataset</a></li>\n","        </ul>\n","        <li><a href=\"#Import-libraries\">Import libraries</a></li>\n","        <li><a href=\"#Load-the-dataset\">Load the dataset</a></li>\n","        <li><a href=\"#Pre-Processing\">Pre-Processing</a></li>\n","        <ul>\n","            <li><a href=\"#What-is-Data-Augmentation?\">What is Data Augmentation?</a></li>\n","            <li><a href=\"#Execute-Data-Augmentation\">Execute Data Augmentation</a></li>\n","        </ul>\n","        <li><a href=\"#Modeling\">Modeling</a></li>\n","        <ul>\n","            <li><a href=\"#Model-Settings\">Model Settings</a></li>\n","            <li><a href=\"#Build-Model\">Build Model</a></li> \n","            <li><a href=\"#Model-Performance\">Model Performance</a></li>\n","            <li><a href=\"#Predict-on-Some-Images\">Predict on Some Images</a></li>\n","        </ul>\n","        <li><a href=\"#Conclusion\">Conclusion</a></li>\n","    </ol>\n","</blockquote>"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"text-align: left; background-color: mediumseagreen; color: white; padding: 10px; line-height:1;border-radius:10px\"><span id='Overview'>Overview</span></div>\n"," \n","<h2 style=\"font-size:150%;\"><span id='Task-Detail'>Task Details</span></h2>\n","\n","* Select or create a dataset that includes images of industrial equipment labelled\n","as 'defective' or 'non-defective', with additional labels for the type of defect in\n","defective images.\n","\n","* Train a machine learning model to classify images into the two main categories.\n","\n","* Evaluate the model's performance using classification metrics such as accuracy,\n","precision, and recall.\n","\n","\n","<h2 style=\"font-size:150%;\"><span id='About-Dataset'>About Dataset</span></h2>\n","This dataset provides image data of impellers for submersible pumps.<br/><br/>\n","<table border=\"0\">\n","     <tr style=\"background-color: white !important;\">\n","        <td>\n","            <img src=\"https://static.turbosquid.com/Preview/2020/06/07__08_34_27/11R131.JPGB3B4468C-B515-4E11-92F7-4CA67966DB2BZoom.jpg\" width=\"300\">\n","            <figcaption style=\"text-align:center\">Submersible Pump</figcaption>\n","        </td>\n","        <td>\n","            <img src=\"https://5.imimg.com/data5/WI/KC/MY-6121640/submersible-pump-impeller-500x500.jpg\" width=\"300\">\n","            <figcaption style=\"text-align:center\">Impeller</figcaption>\n","        </td>\n","    </tr>\n"," </table><br/>\n","The image data is labeled with <b>ok(normal)</b> for non-defective equipment and <b>def(defect/anomaly)</b> for defective equipment.\n","\n","<li>Link to DataSet :- <a href=\"https://github.com/Us2id/Classification-of-equipment-as-defective-and-non-defective-.-\"> Link</a></li>"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"text-align: left; background-color: mediumseagreen; color: white; padding: 10px; line-height:1;border-radius:10px\"><span id='Import-libraries'>Import libraries</span></div>"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-01-10T14:18:35.414938Z","iopub.status.busy":"2023-01-10T14:18:35.414461Z","iopub.status.idle":"2023-01-10T14:18:35.586671Z","shell.execute_reply":"2023-01-10T14:18:35.585874Z","shell.execute_reply.started":"2023-01-10T14:18:35.414883Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.image import imread\n","import cv2\n","%matplotlib inline\n","import warnings\n","warnings.filterwarnings('ignore')\n","import holoviews as hv\n","from holoviews import opts\n","hv.extension('bokeh')\n","import json\n","\n","from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from keras.models import Sequential, load_model\n","from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.utils import plot_model\n","from keras import backend\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"text-align: left; background-color: mediumseagreen; color: white; padding: 10px; line-height:1;border-radius:10px\"><span id='Load-the-dataset'>Load the dataset</span></div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-10T14:18:35.596049Z","iopub.status.busy":"2023-01-10T14:18:35.595388Z","iopub.status.idle":"2023-01-10T14:18:35.604162Z","shell.execute_reply":"2023-01-10T14:18:35.603322Z","shell.execute_reply.started":"2023-01-10T14:18:35.596004Z"},"trusted":true},"outputs":[],"source":["train_path = 'C:\\\\Users\\\\usaid\\\\Downloads\\\\casting_data\\\\train'\n","test_path = 'C:\\\\Users\\\\usaid\\\\Downloads\\\\casting_data\\\\test'"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-10T14:18:35.606079Z","iopub.status.busy":"2023-01-10T14:18:35.605490Z","iopub.status.idle":"2023-01-10T14:18:35.899720Z","shell.execute_reply":"2023-01-10T14:18:35.898767Z","shell.execute_reply.started":"2023-01-10T14:18:35.606035Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10,8))\n","ok = plt.imread(train_path + '\\\\ok_front\\\\cast_ok_0_1.jpeg')\n","plt.subplot(1, 2, 1)\n","plt.axis('off')\n","plt.title(\"ok\", weight='bold', size=20)\n","plt.imshow(ok,cmap='gray')\n","plt.show()\n","\n","ng = plt.imread(train_path + '\\\\def_front\\\\cast_def_0_8.jpeg')\n","plt.subplot(1, 2, 2)\n","plt.axis('off')\n","plt.title(\"def\", weight='bold', size=20)\n","plt.imshow(ng,cmap='gray')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"text-align: left; background-color: mediumseagreen; color: white; padding: 10px; line-height:1;border-radius:10px\"><span id='Pre-Processing'>Pre-Processing</span></div>\n","In training models for image classification, <b>Data Augmentation</b> techniques are needed to build more robust models."]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"font-size:150%;\"><span id='What-is-Data-Augmentation?'>What is Data Augmentation?</span></h2>\n","<div class=\"alert alert-success\" role=\"alert\" style=\"border-radius:10px\">\n","    <p>When training with image data without data augmentation, we simply need the specified number of data and create a mini-batch. When executing data augmentation, after acquiring the data, various augmentation techniques are applied to the image to create a new mini-batch. <br/>\n","    The main parameters of data augmentation techniques are as follows : </p>\n","    <ul>\n","        <li><b>rotation_range</b> : Rotate the image (ex. 50 -> rotate randomly in -50°~50°)</li>\n","        <li><b>zoom_range</b> : Zoom in/out on the image (ex. 0.5 -> zoom in/out randomly in 1-0.5~1+0.5)</li>\n","        <li><b>brightness_range</b> : Change the brightness (ex. [0.3,1.0] -> change randomly in [0.3,1.0])</li>\n","        <li><b>vertical_flip</b> : Flip the image upside down</li>\n","        <li><b>horizontal_flip</b> : Flip the image left or right</li>\n","        <li><b>height_shift_range</b> : Move the image up or down in parallel (ex. 0.3 -> move up/down randomly in [-0.3*Height, 0.3*Height])</li>\n","        <li><b>width_shift_range</b> : Move the image left or right in parallel (ex. 0.3 -> move left/right randomly in [-0.3*Width, 0.3*Width])</li>\n","        <li><b>rescale</b> : The image is normalized by multiplying each pixel value by a constant. (ex. 1/255 -> normalize the RGB value of each pixel between 0.0 and 1.0)</li>\n","    </ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-10T14:18:35.903842Z","iopub.status.busy":"2023-01-10T14:18:35.903270Z","iopub.status.idle":"2023-01-10T14:18:36.423867Z","shell.execute_reply":"2023-01-10T14:18:36.423005Z","shell.execute_reply.started":"2023-01-10T14:18:35.903786Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread(train_path + '\\\\ok_front\\\\cast_ok_0_1.jpeg')\n","img_4d = img[np.newaxis]\n","plt.figure(figsize=(25,10))\n","generators = {\"rotation\":ImageDataGenerator(rotation_range=180), \n","              \"zoom\":ImageDataGenerator(zoom_range=0.7), \n","              \"brightness\":ImageDataGenerator(brightness_range=[0.2,1.0]), \n","              \"height_shift\":ImageDataGenerator(height_shift_range=0.7), \n","              \"width_shift\":ImageDataGenerator(width_shift_range=0.7)}\n","\n","plt.subplot(1, 6, 1)\n","plt.title(\"Original\", weight='bold', size=15)\n","plt.imshow(img)\n","plt.axis('off')\n","cnt = 2\n","for param, generator in generators.items():\n","    image_gen = generator\n","    gen = image_gen.flow(img_4d, batch_size=1)\n","    batches = next(gen)\n","    g_img = batches[0].astype(np.uint8)\n","    plt.subplot(1, 6, cnt)\n","    plt.title(param, weight='bold', size=15)\n","    plt.imshow(g_img)\n","    plt.axis('off')\n","    cnt += 1\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"font-size:150%;\"><span id='Execute-Data-Augmentation'>Execute Data Augmentation</span></h2>\n","<div class=\"alert alert-success\" role=\"alert\" style=\"border-radius:10px\">\n","    <p>In Keras, you can pass ImageDataGenerator class as a dataset when training a model, and it creates a mini-batch by randomly applying the parameters. Empirically, if the parameter is set to an extreme high/low value, <u>the image will be strongly converted and the training will be difficult to proceed.</u> In addition, it seems that fine adjustment of parameters is required for each target data or analysis objectives in order to proceed with training successfully.<br></p>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-10T14:18:36.427093Z","iopub.status.busy":"2023-01-10T14:18:36.426737Z","iopub.status.idle":"2023-01-10T14:18:36.432040Z","shell.execute_reply":"2023-01-10T14:18:36.430937Z","shell.execute_reply.started":"2023-01-10T14:18:36.427058Z"},"trusted":true},"outputs":[],"source":["image_gen = ImageDataGenerator(rescale=1/255, \n","                               zoom_range=0.1, \n","                               brightness_range=[0.9,1.0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-10T14:18:36.434128Z","iopub.status.busy":"2023-01-10T14:18:36.433711Z","iopub.status.idle":"2023-01-10T14:18:44.677040Z","shell.execute_reply":"2023-01-10T14:18:44.676047Z","shell.execute_reply.started":"2023-01-10T14:18:36.434091Z"},"trusted":true},"outputs":[],"source":["image_shape = (300,300,1)\n","batch_size = 32\n","\n","train_set = image_gen.flow_from_directory(train_path,\n","                                            target_size=image_shape[:2],\n","                                            color_mode=\"grayscale\",\n","                                            classes={'def_front': 0, 'ok_front': 1},\n","                                            batch_size=batch_size,\n","                                            class_mode='binary',\n","                                            shuffle=True,\n","                                            seed=0)\n","\n","test_set = image_gen.flow_from_directory(test_path,\n","                                           target_size=image_shape[:2],\n","                                           color_mode=\"grayscale\",\n","                                           classes={'def_front': 0, 'ok_front': 1},\n","                                           batch_size=batch_size,\n","                                           class_mode='binary',\n","                                           shuffle=False,\n","                                           seed=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-10T14:18:44.678735Z","iopub.status.busy":"2023-01-10T14:18:44.678329Z","iopub.status.idle":"2023-01-10T14:18:44.686942Z","shell.execute_reply":"2023-01-10T14:18:44.685942Z","shell.execute_reply.started":"2023-01-10T14:18:44.678688Z"},"trusted":true},"outputs":[],"source":["train_set.class_indices"]},{"cell_type":"markdown","metadata":{},"source":["* class 0 : defect \n","* class 1 : ok"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"text-align: left; background-color: mediumseagreen; color: white; padding: 10px; line-height:1;border-radius:10px\"><span id='Modeling'>Modeling</span></div>"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"font-size:150%;\"><span id='Model-Settings'>Model-Settings</span></h2>\n","<div class=\"alert alert-success\" role=\"alert\" style=\"border-radius:10px\">\n","    <p>The elements of the model are listed below.</p>\n","    <ul>\n","        <li><b>Sequential</b> : model container</li>\n","        <li><b>Conv2D</b> : convolutional layer for 2D images\n","            <ul>\n","                <li><b>filters</b> : number of filters\n","                    <ul>\n","                        <li>numbers such as <u>16, 32, 64, 128, 256 and 512</u> tend to be used, and there is a technique to increase the number of filter for the complicated task and decrease it for simple one.</li>\n","                    </ul>\n","                </li>\n","                <li><b>kernel_size</b> : filter size (width * height)\n","                    <ul>\n","                        <li>combinations of odd numbers such as <u>3x3, 5x5, 7x7</u> tend to be used.</li>\n","                    </ul>\n","                </li>\n","                <li><b>strides</b> : window size used for convolution</li>\n","                <li><b>input_shape</b> : size of input images (width/height, color channel)\n","                    <ul>\n","                        <li>if you input color images as it is, the model will need convolutions for 3 RGB channels, which will increase the amount of calculation(graysclaed images need less calculations).</li>\n","                    </ul>\n","                </li>\n","                <li><b>activation</b> : activation function</li>\n","                <li><b>padding</b> : adjust the size of the layer output. When set to 'same', the pixels are filled with 0 so that the input and output sizes are the same.</li>\n","            </ul>\n","        </li>\n","        <li><b>MaxPooling2D</b> : pooling layer for 2D images\n","            <ul>\n","                <li><b>pool_size</b> : specify width/height range and extract the largest pixel in this range to downscale the input</li>\n","                <li><b>strides</b> : window size used for pooling</li>\n","            </ul>\n","        </li>\n","        <li><b>Flatten</b> : convert input to linear vector</li>\n","        <li><b>Dropout</b> : apply dropout and randomly set the input to the unit to 0 to prevent overfitting when updating weights\n","            <ul>\n","                <li><b>rate</b> : ratio of dropping the input to the unit</li>\n","            </ul>\n","        </li>\n","        <li><b>Dense</b> : fully connected layer\n","            <ul>\n","                <li><b>units</b> : number of dimensions of output</li>\n","                <li><b>activation</b> : activation function（binary classification : <u>sigmoid</u>, other objectives : <u>softmax</u>） </li>\n","            </ul>\n","        </li>\n","    </ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-01-10T14:18:44.688973Z","iopub.status.busy":"2023-01-10T14:18:44.688319Z","iopub.status.idle":"2023-01-10T14:18:54.558089Z","shell.execute_reply":"2023-01-10T14:18:54.557222Z","shell.execute_reply.started":"2023-01-10T14:18:44.688908Z"},"trusted":true},"outputs":[],"source":["backend.clear_session()\n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=(7,7), strides=2, input_shape=image_shape, activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n","model.add(Conv2D(filters=32, kernel_size=(3,3), strides=1, input_shape=image_shape, activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n","model.add(Conv2D(filters=64, kernel_size=(3,3), strides=1, input_shape=image_shape, activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n","model.add(Flatten())\n","model.add(Dense(units=224, activation='relu'))\n","model.add(Dropout(rate=0.2))\n","model.add(Dense(units=1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["The figure below shows the model architecture."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-10T14:18:54.561625Z","iopub.status.busy":"2023-01-10T14:18:54.561358Z","iopub.status.idle":"2023-01-10T14:18:55.366076Z","shell.execute_reply":"2023-01-10T14:18:55.364890Z","shell.execute_reply.started":"2023-01-10T14:18:54.561597Z"},"trusted":true},"outputs":[],"source":["plot_model(model, show_shapes=True, expand_nested=True, dpi=60)"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"font-size:150%;\"><span id='Build-Model'>Build-Model</span></h2>\n","<div class=\"alert alert-success\" role=\"alert\" style=\"border-radius:10px\">\n","    Build settings:  \n","    <ul>\n","        <li><b>EarlyStopping</b> : Conditions to stop training early</li>\n","            <ul>\n","                <li>ex. validation loss not improved continuously in 2 epochs</li>\n","            </ul>\n","        <li><b>ModelCheckpoint</b> : Model saving settings for each epoch</li>\n","    </ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-10T14:18:55.373896Z","iopub.status.busy":"2023-01-10T14:18:55.370947Z","iopub.status.idle":"2023-01-10T14:18:55.385757Z","shell.execute_reply":"2023-01-10T14:18:55.384930Z","shell.execute_reply.started":"2023-01-10T14:18:55.373811Z"},"trusted":true},"outputs":[],"source":["model_save_path = 'casting_product_detection.hdf5'\n","early_stop = EarlyStopping(monitor='val_loss',patience=2)\n","checkpoint = ModelCheckpoint(filepath=model_save_path, verbose=1, save_best_only=True, monitor='val_loss')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-01-10T14:18:55.396255Z","iopub.status.busy":"2023-01-10T14:18:55.393582Z","iopub.status.idle":"2023-01-10T14:36:35.613255Z","shell.execute_reply":"2023-01-10T14:36:35.612521Z","shell.execute_reply.started":"2023-01-10T14:18:55.396213Z"},"trusted":true},"outputs":[],"source":["n_epochs = 20\n","results = model.fit_generator(train_set, epochs=n_epochs, validation_data=test_set, callbacks=[early_stop,checkpoint])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-10T14:36:35.616614Z","iopub.status.busy":"2023-01-10T14:36:35.616346Z","iopub.status.idle":"2023-01-10T14:36:35.622911Z","shell.execute_reply":"2023-01-10T14:36:35.621933Z","shell.execute_reply.started":"2023-01-10T14:36:35.616587Z"},"trusted":true},"outputs":[],"source":["model_history = { i:list(map(lambda x: float(x), j)) for i,j in results.history.items() }\n","with open('model_history.json', 'w') as f:\n","    json.dump(model_history, f, indent=4)"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"font-size:150%;\"><span id='Model-Performance'>Model Performance</span></h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-10T14:36:35.635687Z","iopub.status.busy":"2023-01-10T14:36:35.635308Z","iopub.status.idle":"2023-01-10T14:36:35.672717Z","shell.execute_reply":"2023-01-10T14:36:35.671956Z","shell.execute_reply.started":"2023-01-10T14:36:35.635649Z"},"trusted":true},"outputs":[],"source":["losses = pd.DataFrame(model_history)\n","losses.index = map(lambda x : x+1, losses.index)\n","losses.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["Since the loss at the time of training and validation are steadily decreasing for each epoch, and the accuracy at the time of training and the validation are steadily increasing, it can be said that the training is generally successful."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-10T14:36:35.675713Z","iopub.status.busy":"2023-01-10T14:36:35.675442Z","iopub.status.idle":"2023-01-10T14:36:35.915186Z","shell.execute_reply":"2023-01-10T14:36:35.914466Z","shell.execute_reply.started":"2023-01-10T14:36:35.675685Z"},"trusted":true},"outputs":[],"source":["g = hv.Curve(losses.loss, label='Training Loss') * hv.Curve(losses.val_loss, label='Validation Loss') \\\n","    * hv.Curve(losses.accuracy, label='Training Accuracy') * hv.Curve(losses.val_accuracy, label='Validation Accuracy')\n","g.opts(opts.Curve(xlabel=\"Epochs\", ylabel=\"Loss / Accuracy\", width=700, height=400,tools=['hover'],show_grid=True,title='Model Evaluation')).opts(legend_position='bottom')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-10T14:36:35.916771Z","iopub.status.busy":"2023-01-10T14:36:35.916453Z","iopub.status.idle":"2023-01-10T14:36:42.097354Z","shell.execute_reply":"2023-01-10T14:36:42.095862Z","shell.execute_reply.started":"2023-01-10T14:36:35.916736Z"},"trusted":true},"outputs":[],"source":["pred_probability = model.predict_generator(test_set)\n","predictions = pred_probability > 0.5\n","\n","plt.figure(figsize=(10,6))\n","plt.title(\"Confusion Matrix\", size=20, weight='bold')\n","sns.heatmap(\n","    confusion_matrix(test_set.classes, predictions),\n","    annot=True,\n","    annot_kws={'size':14, 'weight':'bold'},\n","    fmt='d',\n","    xticklabels=['Defect', 'OK'],\n","    yticklabels=['Defect', 'OK'])\n","plt.tick_params(axis='both', labelsize=14)\n","plt.ylabel('Actual', size=14, weight='bold')\n","plt.xlabel('Predicted', size=14, weight='bold')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-10T14:36:42.105224Z","iopub.status.busy":"2023-01-10T14:36:42.102838Z","iopub.status.idle":"2023-01-10T14:36:42.121671Z","shell.execute_reply":"2023-01-10T14:36:42.120551Z","shell.execute_reply.started":"2023-01-10T14:36:42.105179Z"},"trusted":true},"outputs":[],"source":["print(classification_report(test_set.classes, predictions, digits=3))"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"font-size:150%;\"><span id='Predict-on-Some-Images'>Predict on Some Images</span></h2>\n","Select images and apply it to the model."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-10T14:36:42.123668Z","iopub.status.busy":"2023-01-10T14:36:42.123155Z","iopub.status.idle":"2023-01-10T14:36:43.833655Z","shell.execute_reply":"2023-01-10T14:36:43.832916Z","shell.execute_reply.started":"2023-01-10T14:36:42.123622Z"},"trusted":true},"outputs":[],"source":["test_cases = ['\\\\ok_front\\\\cast_ok_0_10.jpeg', '\\\\ok_front\\\\cast_ok_0_1026.jpeg', '\\\\ok_front\\\\cast_ok_0_1031.jpeg', '\\\\ok_front\\\\cast_ok_0_1121.jpeg',\n","              '\\\\ok_front\\\\cast_ok_0_1144.jpeg','\\\\def_front\\\\cast_def_0_1059.jpeg', '\\\\def_front\\\\cast_def_0_108.jpeg', '\\\\def_front\\\\cast_def_0_1153.jpeg',\n","              '\\\\def_front\\\\cast_def_0_1238.jpeg', '\\\\def_front\\\\cast_def_0_1269.jpeg']\n","plt.figure(figsize=(20,8))\n","for i in range(len(test_cases)):\n","    img_pred = cv2.imread(test_path + test_cases[i], cv2.IMREAD_GRAYSCALE)\n","    img_pred = img_pred / 255 # rescale\n","    prediction = model.predict(img_pred.reshape(1, *image_shape))\n","    \n","    img = cv2.imread(test_path + test_cases[i])\n","    label = test_cases[i].split(\"_\")[0]\n","    \n","    plt.subplot(2, 5, i+1)\n","    parts = test_cases[i].split('\\\\')\n","    plt.title(f\"{parts[2]}\\n Actual Label : {label}\", weight='bold', size=12)\n","    # Predicted Class : defect\n","    if (prediction < 0.5):\n","        predicted_label = \"def\"\n","        prob = (1-prediction.sum()) * 100\n","    # Predicted Class : OK\n","    else:\n","        predicted_label = \"ok\"\n","        prob = prediction.sum() * 100\n","        \n","    cv2.putText(img=img, text=f\"Predicted Label : {predicted_label}\", org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=(255, 0, 255), thickness=2)\n","    cv2.putText(img=img, text=f\"Probability : {'{:.3f}'.format(prob)}%\", org=(10, 280), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.7, color=(0, 255, 0), thickness=2)\n","    plt.imshow(img,cmap='gray')\n","    plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"text-align: left; background-color: mediumseagreen; color: white; padding: 10px; line-height:1;border-radius:10px\"><span id='Conclusion'>Conclusion</span></div>\n","\n","<div class=\"alert alert-success\" role=\"alert\" style=\"border-radius:10px\">\n","    <ul>\n","        <li><b>Data augmentation</b> proces can be easily incorporated into training process by using ImageDataGenerator.</li>\n","        <li>In data augmentation process, we should avoid excessive conversion and may require subtle adjustments depending on the dataset.</li>\n","        <li>According to the result of model interpretation, it was found that <b>the scratches/holes on the surface of the products and the unevenness around the products</b> are regarded as the important features of defective products.</li>\n","        <li>Since we successfully built a model with relatively high accuracy, it is considered possible to incorporate the model into the camera of the inspection line and proceed with the automation of inspection.\n","        </li>\n","        <li>Link to DataSet :- <a href=\"https://github.com/Us2id/Classification-of-equipment-as-defective-and-non-defective-.-\"> Link</a>\n","        </li>\n","    </ul>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<button class=\"label alert-success\" style=\"border-radius:10px;padding:10px;font-size:18px\"><a href=\"#top\" style=\"color:green;\"><b>Table of Contents</b></a></button>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
